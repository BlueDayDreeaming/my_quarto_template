# 第 2 章：统计学习

## 2.1 什么是统计学习？

统计学习是围绕着使用**输入变量** (X) 来预测或推断**输出变量** (Y) 的一套方法。

它们之间的关系可以用以下通用公式表示：

$$Y = f(X) + \epsilon$$

* **Y**: 输出变量，也称为响应变量或因变量。
* **X**: 输入变量 $(X_1, X_2, ..., X_p)$，也称为预测变量、自变量或特征。
* **f**: 一个未知的固定函数，代表 X 提供关于 Y 的系统性信息。统计学习的核心目标就是估计 f。
* **ϵ**: 一个随机误差项，与 X 无关且平均值为零。它代表了所有无法由 X 解释的变异，是不可约的。

---

### 为什么要估计 f？

估计 f 主要有两个目的：**预测**和**推断**。

#### 1. 预测 (Prediction)

* **目标**: 当输入 X 已知时，预测输出 Y 的值。
* **方法**: 使用 f 的估计值 $\hat{f}$ 来进行预测，即 $\hat{Y} = \hat{f}(X)$。
* **误差**: 预测的准确性取决于两种误差：
    * **可约误差 (Reducible Error)**: 由于我们的估计 $\hat{f}$ 不完美而引入的误差。我们可以通过选择更好的统计学习方法来减小这种误差。
    * **不可约误差 (Irreducible Error)**: 来自于随机项 $\epsilon$ 的误差。无论我们对 f 的估计多么好，都无法减少这种误差。
* **误差分解**: 预测值与真实值之间的期望平方差可以分解为：
    $E(Y-\hat{Y})^{2} = \underbrace{[f(X)-\hat{f}(X)]^{2}}_{\text{可约}} + \underbrace{Var(\epsilon)}_{\text{不可约}}$

#### 2. 推断 (Inference)

* **目标**: 理解 X 和 Y 之间的关系，而不仅仅是进行预测。
* **关键问题**：
    * 哪些预测变量与响应变量显著相关？
    * 每个预测变量与响应变量之间的关系是什么（例如，正相关或负相关）？
    * 这种关系是线性的还是更复杂的？

---

### 我们如何估计 f？

我们使用**训练数据** $\{(x_1, y_1), (x_2, y_2), ..., (x_n, y_n)\}$ 来让我们的算法学习如何估计 f。方法主要分为两类：

#### 1. 参数方法 (Parametric Methods)

* **流程**: 这是一种两步法。
    1.  **假设模型形式**: 首先，对 f 的函数形式做一个假设。例如，假设 f 是一个线性模型：$f(X) = \beta_{0} + \beta_{1}X_{1} + \dots + \beta_{p}X_{p}$。
    2.  **拟合模型**: 使用训练数据来估算模型中的参数（例如，$\beta_0, \beta_1, \dots, \beta_p$）。
* **优点**: 将估算一个任意函数 f 的复杂问题简化为估算一组参数的问题。
* **缺点**: 选择的模型形式可能与真实的 f 不符，导致估算效果差。更复杂、更灵活的模型可能导致**过拟合 (overfitting)**，即模型过度地学习了训练数据中的噪声。

#### 2. 非参数方法 (Non-Parametric Methods)

* **流程**: 不对 f 的函数形式做明确假设，而是寻求一个能尽可能贴近数据点的估算。
* **优点**: 能够拟合更广泛形状的 f，避免了因模型形式选择错误而带来的风险。
* **缺点**: 需要非常大量的观测数据才能得到准确的估算。也容易发生过拟合。

---

### 其他核心概念

#### 预测准确性与模型可解释性的权衡

* 一般而言，一个方法的灵活性越高，其可解释性就越低。
* **不灵活的模型** (如线性回归) 可解释性很强，但可能不够准确。
* **高度灵活的模型** (如支持向量机、深度学习) 可能非常准确，但通常难以解释，像一个“黑箱”。
* 选择哪种方法取决于我们的目标是**推断**还是**预测**。

#### 监督学习 vs. 无监督学习

* **监督学习 (Supervised Learning)**: 每个观测数据 $x_i$ 都有一个与之相关的响应变量 $y_i$。目标是预测或推断。
* **无监督学习 (Unsupervised Learning)**: 每个观测数据 $x_i$ 没有相关的响应变量 $y_i$。目标是发现数据中的结构，例如**聚类分析 (cluster analysis)**。

#### 回归 vs. 分类

* **回归问题 (Regression)**: 响应变量 Y 是定量的（数值型）。
* **分类问题 (Classification)**: 响应变量 Y 是定性的（类别型）。

## 2.2 评估模型准确性

在统计学中没有“免费的午餐”：没有任何一种方法在所有可能的数据集上都优于其他所有方法。因此，评估模型性能至关重要。

### 衡量拟合质量

#### 1. 回归设定

* **均方误差 (Mean Squared Error, MSE)**: 是最常用的衡量标准，计算公式为：
    $$MSE = \frac{1}{n}\sum_{i=1}^{n}(y_i - \hat{f}(x_i))^2$$
* **训练 MSE vs. 测试 MSE**: 我们真正关心的是模型在未见过的**测试数据**上的表现（测试 MSE），而不是在用于训练模型的**训练数据**上的表现（训练 MSE）。
* **过拟合 (Overfitting)**: 当一个模型在训练数据上得到很低的 MSE，但在测试数据上得到很高的 MSE 时，我们就称之为过拟合。这是因为模型学习了训练数据中的随机噪声，而不是真实的潜在规律。
* **测试 MSE 的 U 形曲线**: 随着模型灵活性的增加，训练 MSE 会持续下降，但测试 MSE 通常会先下降后上升，呈现 U 形。

#### 2. 偏差-方差权衡 (The Bias-Variance Trade-Off)

测试 MSE 的 U 形曲线是**偏差 (Bias)** 和**方差 (Variance)** 这两个相互竞争的属性导致的。预期测试 MSE 可以分解为：

$$E(y_0 - \hat{f}(x_0))^2 = Var(\hat{f}(x_0)) + [Bias(\hat{f}(x_0))]^2 + Var(\epsilon)$$

* **方差 (Variance)**: 指的是如果我们用一个不同的训练数据集来估算 f，$\hat{f}$ 会改变多少。更灵活的方法通常有更高的方差。
* **偏差 (Bias)**: 指的是由于用一个简单的模型来近似现实生活中的复杂问题而引入的误差。更灵活的方法通常有更低的偏差。
* **权衡**: 增加模型灵活性会**降低偏差**但**增加方差**。一个好的模型需要在二者之间取得平衡，以达到最低的总测试误差。

#### 3. 分类设定

* **错误率 (Error Rate)**: 是分类问题中量化准确性的最常用方法，即模型预测错误的观测比例。
    $$ \frac{1}{n}\sum_{i=1}^{n}I(y_i \neq \hat{y}_i) $$
* **贝叶斯分类器 (Bayes Classifier)**: 这是一个理论上最优的分类器，它将每个观测值分配给条件概率 $Pr(Y=j|X=x_0)$ 最大的类别。它能达到的最低测试错误率称为**贝叶斯错误率**。
* **K-近邻 (K-Nearest Neighbors, KNN)**: 一种简单而有效的分类方法，它通过一个观测点 $x_0$ 的 K 个最近邻居来估算其类别概率。
    * **K 的选择**: K 的选择对分类器的性能有巨大影响。小的 K 值会产生灵活性高、方差大、偏差小的模型。大的 K 值则相反，灵活性低、方差小、偏差大。
    * **测试错误率的 U 形曲线**: 与回归设定类似，随着灵活性 (1/K) 的增加，测试错误率也呈现 U 形。